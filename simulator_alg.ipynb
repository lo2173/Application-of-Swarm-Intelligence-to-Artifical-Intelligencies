{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import chatbot_puck as cp\n",
    "import model_puck as mp\n",
    "from matplotlib import animation\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing bots\n",
    "choices = ['darkness','shadows','screams','lost']\n",
    "cgpt_w = ['darkness','dread','silence','whispers','creak','beneath','shadows','eerie']\n",
    "cgpt_freq = [2,2,1,1,1,1,1]\n",
    "koala_w = ['darkness','shadows','ominous','alone','haunting','midnight','unsettling','chilling','whispers','shivers']\n",
    "koala_freq =[1]*10\n",
    "claud_w = ['screams','midnight','shadows','glimpse','lost']\n",
    "claud_freq =[1,3,3,2,1]\n",
    "perp_w = ['nightmare']\n",
    "perp_freq = [10]\n",
    "hug_w = ['darkness', 'shadows', 'nightfall', 'solitude', 'whispers', 'unseen', 'veil', 'hushed', 'echoes']\n",
    "hug_freq = [2,1,1,1,1,1,1,1,1]\n",
    "pi_w = ['darkness']\n",
    "pi_freq = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average time:  11.553371222019196\n",
      "Count of 'darkness':  100\n",
      "Count of 'shadows':  0\n",
      "Count of 'screams':  0\n",
      "Count of 'lost':  0\n"
     ]
    }
   ],
   "source": [
    "# Timing testing suite\n",
    "from statistics import mean\n",
    "times = []\n",
    "decision = []\n",
    "for r in range(0,100):\n",
    "    mp1 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp1,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    claud = cp.ChatbotPuck(model =mp1,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    koala = cp.ChatbotPuck(model=mp1,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    perplex = cp.ChatbotPuck(model =mp1,name = \"perplex\",convic_words=perp_w, convic_freq=perp_freq,debug=False)\n",
    "    huggingchat = cp.ChatbotPuck(model=mp1,name=\"huggingchat\",convic_words=hug_w, convic_freq=hug_freq)\n",
    "    pi = cp.ChatbotPuck(model=mp1,name=\"pi\",convic_words=pi_w, convic_freq=pi_freq)\n",
    "    mp1.set_chatbots([cgpt,claud,koala,perplex,huggingchat,pi])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            perplex.update()\n",
    "            huggingchat.update()\n",
    "            pi.update()\n",
    "            done = mp1.update(start)\n",
    "            if mp1.halt:\n",
    "                times.append(done[1])\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(\"average time: \",mean(times))\n",
    "print(\"Count of 'darkness': \", decision.count('darkness'))\n",
    "print(\"Count of 'shadows': \", decision.count('shadows'))\n",
    "print(\"Count of 'screams': \", decision.count('screams'))\n",
    "print(\"Count of 'lost': \", decision.count('lost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_times = mean(times)\n",
    "# average time:  11.553371222019196\n",
    "# Count of 'darkness':  100\n",
    "# Count of 'shadows':  0\n",
    "# Count of 'screams':  0\n",
    "# Count of 'lost':  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_times = mean(times)\n",
    "# average time:  10.522156672477722\n",
    "# Count of 'darkness':  43\n",
    "# Count of 'shadows':  56\n",
    "# Count of 'screams':  1\n",
    "# Count of 'lost':  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_time = mean(times)\n",
    "# average time:  7.582761054039001\n",
    "# Count of 'darkness':  31\n",
    "# Count of 'shadows':  69\n",
    "# Count of 'screams':  0\n",
    "# Count of 'lost':  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_time = mean(times)\n",
    "# average time:  5.17298712015152\n",
    "# Count of 'darkness':  1\n",
    "# Count of 'shadows':  99\n",
    "# Count of 'screams':  0\n",
    "# Count of 'lost':  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5151755690574644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_time = mean(times)\n",
    "two_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Time in Seconds')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Timing plot\n",
    "import matplotlib.pyplot as plt\n",
    "x = [2,3,4,5,6]\n",
    "y = [2.5151755690574644,5.17298712015152,7.582761054039001,10.522156672477722,11.553371222019196]\n",
    "plt.figure\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Effect on Swarm Density on Convergence Time\")\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Amount of Bots\")\n",
    "plt.ylabel(\"Time in Seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Accuracy Simple\n",
    "choices = ['one','two','three','four']\n",
    "bot1_freq = [1,1,1,7]\n",
    "bot2_freq = [1,7,1,1]\n",
    "bot3_freq = [1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m bot1\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     12\u001b[0m bot2\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mbot3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m done \u001b[38;5;241m=\u001b[39m mp2\u001b[38;5;241m.\u001b[39mupdate(start)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mp2\u001b[38;5;241m.\u001b[39mhalt:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:164\u001b[0m, in \u001b[0;36mChatbotPuck.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_F\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# print(self.name ,'F: ', self.F)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhalt:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:129\u001b[0m, in \u001b[0;36mChatbotPuck.update_F\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# ?print('NEW_INDEX: ',new_index)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallwords[new_index]\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m new_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm))]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoice:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:101\u001b[0m, in \u001b[0;36mChatbotPuck.update_sim\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_sim\u001b[39m(\u001b[38;5;28mself\u001b[39m,word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 101\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword\n\u001b[0;32m    103\u001b[0m     e_botword \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(word)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[0;32m    839\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 840\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(input_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sbert_config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[0;32m    136\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[38;5;241m=\u001b[39minput_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     28\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:49\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_t5_model(model_name_or_path, config, cache_dir)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3473\u001b[0m     (\n\u001b[0;32m   3474\u001b[0m         model,\n\u001b[0;32m   3475\u001b[0m         missing_keys,\n\u001b[0;32m   3476\u001b[0m         unexpected_keys,\n\u001b[0;32m   3477\u001b[0m         mismatched_keys,\n\u001b[0;32m   3478\u001b[0m         offload_index,\n\u001b[0;32m   3479\u001b[0m         error_msgs,\n\u001b[1;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3732\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3731\u001b[0m     _loaded_keys \u001b[38;5;241m=\u001b[39m loaded_keys\n\u001b[1;32m-> 3732\u001b[0m \u001b[43mset_initialized_submodules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_loaded_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3733\u001b[0m \u001b[38;5;66;03m# This will only initialize submodules that are not marked as initialized by the line above.\u001b[39;00m\n\u001b[0;32m   3734\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(model\u001b[38;5;241m.\u001b[39m_initialize_weights)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:514\u001b[0m, in \u001b[0;36mset_initialized_submodules\u001b[1;34m(model, state_dict_keys)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_name, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[0;32m    513\u001b[0m     loaded_keys \u001b[38;5;241m=\u001b[39m [k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m state_dict_keys \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(loaded_keys)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    515\u001b[0m         module\u001b[38;5;241m.\u001b[39m_is_hf_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1818\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   1820\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1818\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   1820\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1818\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state_dict_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m   1820\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, destination, prefix, local_metadata)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1815\u001b[0m, in \u001b[0;36mModule.state_dict\u001b[1;34m(self, destination, prefix, keep_vars, *args)\u001b[0m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(destination, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1813\u001b[0m     destination\u001b[38;5;241m.\u001b[39m_metadata[prefix[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m local_metadata\n\u001b[1;32m-> 1815\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_to_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1726\u001b[0m, in \u001b[0;36mModule._save_to_state_dict\u001b[1;34m(self, destination, prefix, keep_vars)\u001b[0m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1726\u001b[0m         destination[prefix \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m param \u001b[38;5;28;01mif\u001b[39;00m keep_vars \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, buf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Accuracy Simple\n",
    "decision = []\n",
    "for r in range(0,100):\n",
    "    mp2 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    bot1 = cp.ChatbotPuck(model=mp2,name = 'bot1',convic_words=choices,convic_freq=bot1_freq)\n",
    "    bot2 = cp.ChatbotPuck(model=mp2,name = 'bot2',convic_words=choices,convic_freq=bot2_freq)\n",
    "    bot3 = cp.ChatbotPuck(model=mp2,name = 'bot3',convic_words=choices,convic_freq=bot3_freq)\n",
    "    mp2.set_chatbots([bot1,bot2,bot3])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            bot1.update()\n",
    "            bot2.update()\n",
    "            bot3.update()\n",
    "            done = mp2.update(start)\n",
    "            if mp2.halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(\"Count of 'one': \",decision.count('one'))\n",
    "print(\"Count of 'two': \", decision.count('two'))\n",
    "print(\"Count of 'three': \",decision.count('three'))\n",
    "print(\"Count of 'four': \",decision.count('four'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'one':  0\n",
      "Count of 'two':  27\n",
      "Count of 'three':  0\n",
      "Count of 'four':  41\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of 'one': \",decision.count('one'))\n",
    "print(\"Count of 'two': \", decision.count('two'))\n",
    "print(\"Count of 'three': \",decision.count('three'))\n",
    "print(\"Count of 'four': \",decision.count('four'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Complex\n",
    "choices = ['good','bad','sheep','yellow']\n",
    "bot1_word = ['great', 'like', 'red', 'blue']\n",
    "bot1_freq = [1,1,1,1]\n",
    "bot2_word = ['pink', 'goat', 'heart', 'wallet']\n",
    "bot2_freq = [1,7,1,1]\n",
    "bot3_word = ['mattress', 'door','evil', 'car']\n",
    "bot3_freq = [1,1,7,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100000\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m         \u001b[43mbot1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         bot2\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     14\u001b[0m         bot3\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:164\u001b[0m, in \u001b[0;36mChatbotPuck.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_F\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# print(self.name ,'F: ', self.F)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhalt:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:129\u001b[0m, in \u001b[0;36mChatbotPuck.update_F\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# ?print('NEW_INDEX: ',new_index)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallwords[new_index]\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m new_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm))]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoice:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:101\u001b[0m, in \u001b[0;36mChatbotPuck.update_sim\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_sim\u001b[39m(\u001b[38;5;28mself\u001b[39m,word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 101\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword\n\u001b[0;32m    103\u001b[0m     e_botword \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(word)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[0;32m    839\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 840\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(input_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sbert_config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[0;32m    136\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[38;5;241m=\u001b[39minput_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     28\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:49\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_t5_model(model_name_or_path, config, cache_dir)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3236\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[0;32m   3235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 3236\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   3238\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   3239\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:882\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[43mBertEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m BertEncoder(config)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;241m=\u001b[39m BertPooler(config) \u001b[38;5;28;01mif\u001b[39;00m add_pooling_layer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:185\u001b[0m, in \u001b[0;36mBertEmbeddings.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mmax_position_embeddings, config\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mtype_vocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:144\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs),\n\u001b[0;32m    143\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_weight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m [num_embeddings, embedding_dim], \\\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:153\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[38;5;241m=\u001b[39mtensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_no_grad_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Accuracy Comple\n",
    "decision = []\n",
    "for r in range(0,100):\n",
    "    mp3 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    bot1 = cp.ChatbotPuck(model=mp3,name = 'bot1',convic_words=bot1_word,convic_freq=bot1_freq)\n",
    "    bot2 = cp.ChatbotPuck(model=mp3,name = 'bot2',convic_words=bot2_word,convic_freq=bot2_freq)\n",
    "    bot3 = cp.ChatbotPuck(model=mp3,name = 'bot3',convic_words=bot3_word,convic_freq=bot3_freq)\n",
    "    mp3.set_chatbots([bot1,bot2,bot3])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            bot1.update()\n",
    "            bot2.update()\n",
    "            bot3.update()\n",
    "            done = mp3.update(start)\n",
    "            if mp3.halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(\"Count of 'good': \",decision.count('good'))\n",
    "print(\"Count of 'bad': \", decision.count('bad'))\n",
    "print(\"Count of 'sheep': \",decision.count('sheep'))\n",
    "print(\"Count of 'yellow': \",decision.count('yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Count of 'good':  0\n",
      "Count of 'bad':  8\n",
      "Count of 'sheep':  5\n",
      "Count of 'yellow':  0\n"
     ]
    }
   ],
   "source": [
    "print(len(decision))\n",
    "print(\"Count of 'good': \",decision.count('good'))\n",
    "print(\"Count of 'bad': \", decision.count('bad'))\n",
    "print(\"Count of 'sheep': \",decision.count('sheep'))\n",
    "print(\"Count of 'yellow': \",decision.count('yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shakespearan humanity responses\n",
    "choices = ['mortality','dirt','poverty','greed']\n",
    "cgpt_w = ['putrescence','foulness','decay','putridity','corrruption','rankness','pestilence','putrefaction', 'loathsome decay', 'abhorence']\n",
    "cgpt_freq = [1]*10\n",
    "koala_w = ['foulness', 'rankness','putridness','filth','pestilence','corruption','putrefaction','rot','rank','foul']\n",
    "koala_freq =[1]*10\n",
    "claud_w = ['fetid','rankness','putrescence','malodorousness','foulness','putridity', 'fetor','stenchfulness']\n",
    "claud_freq =[3,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100000\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m         \u001b[43mcgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         claud\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     14\u001b[0m         koala\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:164\u001b[0m, in \u001b[0;36mChatbotPuck.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_F\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# print(self.name ,'F: ', self.F)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhalt:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:129\u001b[0m, in \u001b[0;36mChatbotPuck.update_F\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# ?print('NEW_INDEX: ',new_index)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallwords[new_index]\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m new_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimm))]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchoice:\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\OneDrive\\Documents\\HOMEWORK\\COSIW\\chatbot_puck.py:101\u001b[0m, in \u001b[0;36mChatbotPuck.update_sim\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_sim\u001b[39m(\u001b[38;5;28mself\u001b[39m,word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 101\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword\n\u001b[0;32m    103\u001b[0m     e_botword \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(word)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[0;32m    839\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 840\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(input_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sbert_config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[0;32m    136\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[38;5;241m=\u001b[39minput_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     28\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:49\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_t5_model(model_name_or_path, config, cache_dir)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3236\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[0;32m   3235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 3236\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   3238\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   3239\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:882\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[43mBertEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m BertEncoder(config)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;241m=\u001b[39m BertPooler(config) \u001b[38;5;28;01mif\u001b[39;00m add_pooling_layer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:185\u001b[0m, in \u001b[0;36mBertEmbeddings.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mmax_position_embeddings, config\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mtype_vocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size)\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:144\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs),\n\u001b[0;32m    143\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_weight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m [num_embeddings, embedding_dim], \\\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:153\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[38;5;241m=\u001b[39mtensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd)\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_no_grad_normal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ibuku\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "decision = []\n",
    "for r in range(0,100):\n",
    "    mp4 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp4,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    claud = cp.ChatbotPuck(model =mp4,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    koala = cp.ChatbotPuck(model=mp4,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    mp4.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp4.update(start)\n",
    "            if mp4.halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(len(decision))\n",
    "print(\"Count of 'mortality': \", decision.count('mortality'))\n",
    "print(\"Count of 'dirt': \", decision.count('dirt'))\n",
    "print(\"Count of 'poverty': \", decision.count('poverty'))\n",
    "print(\"Count of 'greed': \", decision.count('greed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "Count of 'mortality':  0\n",
      "Count of 'dirt':  87\n",
      "Count of 'poverty':  0\n",
      "Count of 'greed':  0\n"
     ]
    }
   ],
   "source": [
    "print(len(decision))\n",
    "print(\"Count of 'mortality': \", decision.count('mortality'))\n",
    "print(\"Count of 'dirt': \", decision.count('dirt'))\n",
    "print(\"Count of 'poverty': \", decision.count('poverty'))\n",
    "print(\"Count of 'greed': \", decision.count('greed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "d1 = pandas.read_json('./train.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "a = []\n",
    "for i in range(0,20):\n",
    "    a.append(random.randint(0,len(d1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "for i in a:\n",
    "    index = i\n",
    "    while len(d1.iloc[index]['answers']['raw'].keys()) < 4:\n",
    "        index= random.randint(0,500)\n",
    "    questions.append(d1.iloc[index]['question']['original'])\n",
    "    answers.append(d1.iloc[index]['answers']['raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cheap restaurant', 'hospital', 'school', 'convenience stores']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(answers[2].keys())[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name An Occupation Where People Are Paid To Tell Others What To Do (More Specific Than Boss).\n",
    "choices = list(answers[0].keys())[0:4]\n",
    "cgpt_w = ['coordinator','supervisor','manager','director','team leader']\n",
    "cgpt_freq = [1,3,3,1,2]\n",
    "koala_w = ['supervisor', 'foreman', 'manager','management consultant','team leader']\n",
    "koala_freq =[4,3,1,1,1]\n",
    "claud_w = ['chief of police', 'sous chef', 'drum major', 'choir director', 'judge', 'cruise director', 'foreman', 'manager']\n",
    "claud_freq =[1,1,1,1,1,1,1,3]\n",
    "c = questions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name An Occupation Where People Are Paid To Tell Others What To Do (More Specific Than Boss). \n",
      "20\n",
      "Decision count of  doctor :  20\n",
      "Decision count of  lawyer :  0\n",
      "Decision count of  fitness trainer :  0\n",
      "Decision count of  accountant/broker :  0\n",
      "-------------------------------------------------\n",
      "CGPT CHOICE:  doctor\n",
      "CLAUD CHOICE:  doctor\n",
      "KOALA CHOICE:  doctor\n"
     ]
    }
   ],
   "source": [
    "decision = []\n",
    "cgpt_c = None\n",
    "claud_c = None\n",
    "koala_c = None\n",
    "for r in range(0,20):\n",
    "    mp5 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp5,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    cgpt_c = cgpt.choice\n",
    "    claud = cp.ChatbotPuck(model =mp5,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    claud_c = claud.choice\n",
    "    koala = cp.ChatbotPuck(model=mp5,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    koala_c = koala.choice\n",
    "    mp5.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp5.update(start)\n",
    "            if mp5 .halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(c)\n",
    "print(len(decision))\n",
    "for c in choices:\n",
    "    print(\"Decision count of \",c,\": \", decision.count(c))\n",
    "print('-------------------------------------------------')\n",
    "print('CGPT CHOICE: ', cgpt_c)\n",
    "print('CLAUD CHOICE: ', claud_c)\n",
    "print('KOALA CHOICE: ',koala_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name A Reason Why Its Harder To Get Out Of Bed On Some Days Than On Others.\n",
    "choices = list(answers[1].keys())[0:4]\n",
    "cgpt_w = ['lack of sleep', 'fatigue','stress', 'lack of motivation', 'despression','weather','illness','emotional distress','lack of energy','sleeping inconsistencies']\n",
    "cgpt_freq = [1]*10\n",
    "koala_w = ['exhaustion']\n",
    "koala_freq =[10]\n",
    "claud_w = ['lack of sleep', 'weekends', 'hormonal changes', 'weather', 'depression', 'lack of motivaton', 'illness', 'tiredness', 'comfort']\n",
    "claud_freq =[1,1,1,1,1,1,1,2,1]\n",
    "c= questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name A Reason Why Its Harder To Get Out Of Bed On Some Days Than On Others. \n",
      "20\n",
      "Decision count of  tired :  20\n",
      "Decision count of  sick :  0\n",
      "Decision count of  bad weather :  0\n",
      "Decision count of  going to work/school :  0\n",
      "-------------------------------------------------\n",
      "CGPT CHOICE:  tired\n",
      "CLAUD CHOICE:  tired\n",
      "KOALA CHOICE:  tired\n"
     ]
    }
   ],
   "source": [
    "decision = []\n",
    "cgpt_c = None\n",
    "claud_c = None\n",
    "koala_c = None\n",
    "for r in range(0,20):\n",
    "    mp5 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp5,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    cgpt_c = cgpt.choice\n",
    "    claud = cp.ChatbotPuck(model =mp5,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    claud_c = claud.choice\n",
    "    koala = cp.ChatbotPuck(model=mp5,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    koala_c = koala.choice\n",
    "    mp5.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp5.update(start)\n",
    "            if mp5 .halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(c)\n",
    "print(len(decision))\n",
    "for c in choices:\n",
    "    print(\"Decision count of \",c,\": \", decision.count(c))\n",
    "print('-------------------------------------------------')\n",
    "print('CGPT CHOICE: ', cgpt_c)\n",
    "print('CLAUD CHOICE: ', claud_c)\n",
    "print('KOALA CHOICE: ',koala_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `Name a kind of place that's known for serving really bad food. `\n",
    "choices = list(answers[2].keys())[0:4]\n",
    "cgpt_w = ['dive diner', 'fast food', 'gas station', 'cafeteria','school', 'microwave meal restaurant', 'dollar store cafe', 'truck stop diner']\n",
    "cgpt_freq = [1,2,1,1,2,1,1,1]\n",
    "koala_w = ['fast food', 'school', 'prison', 'airline', 'hospital', 'tourist trap', 'roadside diner', 'budget buffets']\n",
    "koala_freq =[1,1,2,1,2,1,1,1]\n",
    "claud_w = ['prison', 'fast food', 'hospital', 'school', 'cheap buffets', 'airplanes','baseball stadium', 'movie theater', 'retirement homes']\n",
    "claud_freq =[1,1,1,1,2,1,1,1,1]\n",
    "c = questions[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name a kind of place that's known for serving really bad food. \n",
      "20\n",
      "Decision count of  cheap restaurant :  0\n",
      "Decision count of  hospital :  10\n",
      "Decision count of  school :  10\n",
      "Decision count of  convenience stores :  0\n",
      "-------------------------------------------------\n",
      "CGPT CHOICE:  school\n",
      "CLAUD CHOICE:  cheap restaurant\n",
      "KOALA CHOICE:  hospital\n"
     ]
    }
   ],
   "source": [
    "decision = []\n",
    "cgpt_c = None\n",
    "claud_c = None\n",
    "koala_c = None\n",
    "for r in range(0,20):\n",
    "    mp5 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp5,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    cgpt_c = cgpt.choice\n",
    "    claud = cp.ChatbotPuck(model =mp5,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    claud_c = claud.choice\n",
    "    koala = cp.ChatbotPuck(model=mp5,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    koala_c = koala.choice\n",
    "    mp5.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp5.update(start)\n",
    "            if mp5 .halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(c)\n",
    "print(len(decision))\n",
    "for c in choices:\n",
    "    print(\"Decision count of \",c,\": \", decision.count(c))\n",
    "print('-------------------------------------------------')\n",
    "print('CGPT CHOICE: ', cgpt_c)\n",
    "print('CLAUD CHOICE: ', claud_c)\n",
    "print('KOALA CHOICE: ',koala_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name A Food That Can be Eaten Directly From Its Container.\n",
    "choices = list(answers[3].keys())[0:4]\n",
    "cgpt_w = ['yogurt', 'ice cream', 'hummus', 'peanut butter', 'salsa', 'cottage cheese', 'fruit cups','pudding']\n",
    "cgpt_freq = [2,1,2,1,1,1,1,1]\n",
    "koala_w = ['ice cream', 'yogurt']\n",
    "koala_freq =[3,7]\n",
    "claud_w = ['chips', 'yogurt', 'apples','celery sticks', 'granola bars','candy', 'deli meat', 'bananas', 'cheerios']\n",
    "claud_freq =[1,2,1,1,1,1,1,1,1]\n",
    "c = questions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name A Food That Can be Eaten Directly From Its Container. \n",
      "20\n",
      "Decision count of  ice cream :  0\n",
      "Decision count of  yogurt :  20\n",
      "Decision count of  chips :  0\n",
      "Decision count of  tuna :  0\n",
      "-------------------------------------------------\n",
      "CGPT CHOICE:  yogurt\n",
      "CLAUD CHOICE:  yogurt\n",
      "KOALA CHOICE:  yogurt\n"
     ]
    }
   ],
   "source": [
    "decision = []\n",
    "cgpt_c = None\n",
    "claud_c = None\n",
    "koala_c = None\n",
    "for r in range(0,20):\n",
    "    mp5 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp5,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    cgpt_c = cgpt.choice\n",
    "    claud = cp.ChatbotPuck(model =mp5,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    claud_c = claud.choice\n",
    "    koala = cp.ChatbotPuck(model=mp5,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    koala_c = koala.choice\n",
    "    mp5.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp5.update(start)\n",
    "            if mp5 .halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(c)\n",
    "print(len(decision))\n",
    "for c in choices:\n",
    "    print(\"Decision count of \",c,\": \", decision.count(c))\n",
    "print('-------------------------------------------------')\n",
    "print('CGPT CHOICE: ', cgpt_c)\n",
    "print('CLAUD CHOICE: ', claud_c)\n",
    "print('KOALA CHOICE: ',koala_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name A Fruit Put In Margaritas\n",
    "choices = list(answers[4].keys())[0:4]\n",
    "cgpt_w = ['lime', 'orange', 'mango', 'strawberry' ]\n",
    "cgpt_freq = [7,1,1,1]\n",
    "koala_w = ['lime']\n",
    "koala_freq =[10]\n",
    "claud_w = ['lime','lemon','orange','pineapple','strawberry','peach','mango','watermelon','raspberry']\n",
    "claud_freq =[2,1,1,1,1,1,1,1,1]\n",
    "c = questions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name A Fruit Put In Margaritas\n",
      "20\n",
      "Decision count of  lime :  20\n",
      "Decision count of  strawberries :  0\n",
      "Decision count of  lemon :  0\n",
      "Decision count of  pinapple :  0\n",
      "-------------------------------------------------\n",
      "CGPT CHOICE:  lime\n",
      "CLAUD CHOICE:  lime\n",
      "KOALA CHOICE:  lime\n"
     ]
    }
   ],
   "source": [
    "decision = []\n",
    "cgpt_c = None\n",
    "claud_c = None\n",
    "koala_c = None\n",
    "for r in range(0,20):\n",
    "    mp5 = mp.ModelPuck(choices=choices,debug=False)\n",
    "    cgpt = cp.ChatbotPuck(model=mp5,name = 'cgpt',convic_words=cgpt_w,convic_freq=cgpt_freq,debug=False)\n",
    "    cgpt_c = cgpt.choice\n",
    "    claud = cp.ChatbotPuck(model =mp5,name = \"claud\",convic_words=claud_w, convic_freq=claud_freq,debug=False)\n",
    "    claud_c = claud.choice\n",
    "    koala = cp.ChatbotPuck(model=mp5,name='koala',convic_words=koala_w,convic_freq=koala_freq)\n",
    "    koala_c = koala.choice\n",
    "    mp5.set_chatbots([cgpt,claud,koala])\n",
    "    start = time.time()\n",
    "    for i in range(0,100000):\n",
    "        if(i>0):\n",
    "            cgpt.update()\n",
    "            claud.update()\n",
    "            koala.update()\n",
    "            done = mp5.update(start)\n",
    "            if mp5 .halt:\n",
    "                decision.append(done[0])\n",
    "                break\n",
    "print(c)\n",
    "print(len(decision))\n",
    "for c in choices:\n",
    "    print(\"Decision count of \",c,\": \", decision.count(c))\n",
    "print('-------------------------------------------------')\n",
    "print('CGPT CHOICE: ', cgpt_c)\n",
    "print('CLAUD CHOICE: ', claud_c)\n",
    "print('KOALA CHOICE: ',koala_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
